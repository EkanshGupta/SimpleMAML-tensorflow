{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154517e4-9cdf-4276-967e-3593a8c52617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 03:31:51.458920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-03-16 03:31:57.229877: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-03-16 03:31:57.231730: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-12.3.0/mvapich2-2.3.7-1-qv3gjagtbx5e3rlbdy6iy2sfczryftyt/lib:/opt/slurm/current/lib:/opt/pmix/4.2.6/lib:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-12.3.0/libpciaccess-0.17-pjfe4ct4gfm5k26s36hmewhbz4k232dl/lib:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-11.3.1/gcc-12.3.0-ukkkutsxfl5kpnnaxflpkq2jtliwthfz/lib64:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-11.3.1/gcc-12.3.0-ukkkutsxfl5kpnnaxflpkq2jtliwthfz/lib:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-12.3.0/zlib-1.2.13-3qhjpij2pji47kfanmlflvwk5ljcn5lh/lib:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-12.3.0/mpc-1.3.1-3zvixith5i243hwiill4exyu3lf2q6ad/lib:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-12.3.0/mpfr-4.2.0-tox4bdsc25zr763rnq5gzlukfbvw7uj7/lib:/usr/local/pace-apps/spack/packages/linux-rhel9-x86_64_v3/gcc-12.3.0/gmp-6.2.1-n7dzsse5e3f6w5z6q6cuqursydg6yypo/lib::\n",
      "2025-03-16 03:31:57.231912: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-16 03:31:57.232096: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login-phoenix-rh9-2.pace.gatech.edu): /proc/driver/nvidia/version does not exist\n",
      "2025-03-16 03:31:57.233795: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-16 03:31:57.235948: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"eeg_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  256       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  64        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC multiple                  768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC multiple                  2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  98        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,362\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train Loss: 0.6932\n",
      "Step 0/5 completed\n",
      "Train Loss: 0.6921\n",
      "Step 1/5 completed\n",
      "Train Loss: 0.6911\n",
      "Step 2/5 completed\n",
      "Train Loss: 0.6901\n",
      "Step 3/5 completed\n",
      "Train Loss: 0.6887\n",
      "Step 4/5 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 03:32:06.616934: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-03-16 03:32:06.840118: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2700000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5056\n",
      "Test accuracy: 0.4797\n",
      "Model: \"eeg_net_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           multiple                  256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc multiple                  64        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi multiple                  768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_20 (Averag multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab multiple                  2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc multiple                  64        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_21 (Averag multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  98        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,362\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train Loss: 0.6937\n",
      "Step 0/5 completed\n",
      "Train Loss: 0.6928\n",
      "Step 1/5 completed\n",
      "Train Loss: 0.6921\n",
      "Step 2/5 completed\n",
      "Train Loss: 0.6914\n",
      "Step 3/5 completed\n",
      "Train Loss: 0.6904\n",
      "Step 4/5 completed\n",
      "Test accuracy: 0.4994\n",
      "Test accuracy: 0.5148\n",
      "Model: \"eeg_net_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           multiple                  256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc multiple                  64        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_20 (Depthwi multiple                  768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_40 (Averag multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_20 (Separab multiple                  2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc multiple                  64        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_41 (Averag multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  98        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,362\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train Loss: 0.6938\n",
      "Step 0/5 completed\n",
      "Train Loss: 0.6928\n",
      "Step 1/5 completed\n",
      "Train Loss: 0.6921\n",
      "Step 2/5 completed\n",
      "Train Loss: 0.6913\n",
      "Step 3/5 completed\n",
      "Train Loss: 0.6903\n",
      "Step 4/5 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m meta_model \u001b[38;5;241m=\u001b[39m maml\u001b[38;5;241m.\u001b[39mtrain(user_data,i,meta_users,pretrain_lr\u001b[38;5;241m=\u001b[39mpretrain_lr, pretrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m meta_model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights/maml/model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m \u001b[43mmaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_users\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m maml\u001b[38;5;241m.\u001b[39mtest_model(model_params, user_data, unseen_users)\n",
      "Cell \u001b[0;32mIn[1], line 94\u001b[0m, in \u001b[0;36mMAML.test_model\u001b[0;34m(self, model_params, user_data, test_users)\u001b[0m\n\u001b[1;32m     91\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(test_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Convert categorical to class index\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Fine-tune on the support set\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43muser_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m outputs \u001b[38;5;241m=\u001b[39m user_model(test_data)\n\u001b[1;32m     96\u001b[0m predicted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(outputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1089\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1087\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():\n\u001b[0;32m-> 1089\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1091\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1669\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the state of all the metrics in the model.\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m \n\u001b[1;32m   1652\u001b[0m \u001b[38;5;124;03mExamples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[0;32m-> 1669\u001b[0m   \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/metrics.py:253\u001b[0m, in \u001b[0;36mMetric.reset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_states\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Resets all of the metric state variables.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m  This function is called between epochs/steps,\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m  when a metric is evaluated during training.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m   \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:3706\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m   3705\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[0;32m-> 3706\u001b[0m     \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3708\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m get_graph()\u001b[38;5;241m.\u001b[39mas_default():\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:882\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# Note: not depending on the cached value here since this can be used to\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# initialize the variable.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _handle_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle):\n\u001b[0;32m--> 882\u001b[0m   value_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mis_compatible_with(value_tensor\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1540\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1535\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1537\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1540\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1543\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    275\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    279\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from EEGNet_def import EEGNet, fastWeights_EEGNet\n",
    "from utils import generate_user_data\n",
    "import pickle\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import clone_model\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import tracemalloc\n",
    "import random\n",
    "from random import shuffle\n",
    "from copy import deepcopy, copy\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "class MAML:\n",
    "    def __init__(self, model_params, input_shape=(64, 128, 1), num_classes=2, inner_lr=0.001, outer_lr=0.001, \n",
    "                 inner_steps=5, outer_steps=100, fine_tune_steps = 10, num_users=5, support_size=20, query_size=20):\n",
    "        self.inner_steps = inner_steps\n",
    "        self.outer_steps = outer_steps\n",
    "        self.fine_tune_steps = fine_tune_steps\n",
    "        self.num_classes = num_classes\n",
    "        self.inner_lr = inner_lr\n",
    "        self.outer_lr = outer_lr\n",
    "        self.support_size = support_size\n",
    "        self.query_size = query_size\n",
    "        self.num_users = num_users\n",
    "        self.model = self.create_eegnet(num_classes, model_params)\n",
    "        self.meta_optimizer = tf.keras.optimizers.Adam(outer_lr)\n",
    "        self.loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    def create_eegnet(self,num_classes,model_params):\n",
    "        num_channels, num_time_samples, model_dropout, model_kern, model_f1, model_d, model_f2 = model_params\n",
    "        eegnet = EEGNet(nb_classes=num_classes,Chans=num_channels, Samples=num_time_samples, dropoutRate = model_dropout, \n",
    "                kernLength = model_kern, F1 = model_f1, D = model_d, F2 = model_f2)  \n",
    "        eegnet.build((None, num_channels, num_time_samples,1))\n",
    "        return eegnet\n",
    "                \n",
    "    def TrainMAML(self, user_data, test_users):\n",
    "        def InnerUpdate(batch):\n",
    "            support_x,support_y,query_x,query_y = batch\n",
    "            with tf.GradientTape() as taskTape:\n",
    "                loss = self.loss_fn(support_y, self.model(support_x))\n",
    "            \n",
    "            grads = taskTape.gradient(loss, self.model.trainable_weights)\n",
    "            weights = [w - self.inner_lr * g for g, w in zip(grads, self.model.trainable_weights)]\n",
    "            return self.loss_fn(query_y, fastWeights_EEGNet(self.model, weights, query_x))\n",
    "    \n",
    "        total_train_loss=0\n",
    "        test_acc_list = [[] for i in range(len(test_users))]\n",
    "        for idx,user in enumerate(test_users):\n",
    "            support_x, support_y = user_data[user][\"support\"]\n",
    "            query_x, query_y = user_data[user][\"query\"]\n",
    "            test_x, test_y = user_data[user][\"test\"]\n",
    "            with tf.GradientTape() as tape:\t\n",
    "                # loss = tf.map_fn(taskLoss, elems=(support_x,support_y,query_x,query_y),fn_output_signature=tf.float32)\n",
    "                # loss = tf.reduce_sum(batchLoss)\n",
    "                loss = InnerUpdate([support_x,support_y,query_x,query_y])\n",
    "                total_train_loss+=loss\n",
    "            meta_gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.meta_optimizer.apply_gradients(zip(meta_gradients, self.model.trainable_variables))\n",
    "        avg_train_loss = total_train_loss / (len(test_users))\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        return avg_train_loss\n",
    "\n",
    "    def train(self, user_data, train_user, test_users, pretraining_epochs=100, pretrain_lr=0.001, pretrain=False):\n",
    "        train_loss_list=[]\n",
    "        self.model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=pretrain_lr),\n",
    "          metrics=[metrics.SpecificityAtSensitivity(0.5, num_thresholds=50)])\n",
    "        self.model.summary()\n",
    "        for step in range(self.outer_steps):\n",
    "            train_loss_list.append(self.TrainMAML(user_data, test_users))\n",
    "            if step % 1 == 0:\n",
    "                print(f\"Step {step}/{self.outer_steps} completed\")\n",
    "        return self.model\n",
    "\n",
    "    def test_model(self, model_params, user_data, test_users):\n",
    "        acc_fine_tune=[]\n",
    "        for user in test_users:\n",
    "            user_model = self.create_eegnet(self.num_classes, model_params)\n",
    "            user_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "            user_model.load_weights('model_weights/maml/model')\n",
    "            support_x, support_y = user_data[user][\"support\"]\n",
    "            test_data, test_labels = user_data[user][\"test\"]\n",
    "            test_labels = tf.cast(test_labels, tf.int64)\n",
    "            test_labels = tf.argmax(test_labels, axis=1)  # Convert categorical to class index\n",
    "\n",
    "            # Fine-tune on the support set\n",
    "            user_model.fit(support_x, support_y, epochs=self.fine_tune_steps, verbose=0)\n",
    "            outputs = user_model(test_data)\n",
    "            predicted = tf.argmax(outputs, axis=1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, test_labels), tf.float32))\n",
    "            acc_fine_tune.append(accuracy.numpy())\n",
    "        print(f\"Test accuracy: {np.mean(acc_fine_tune):.4f}\")\n",
    "\n",
    "num_classes = 2  # Example binary classification\n",
    "num_users = 10  \n",
    "num_samples = 400  \n",
    "num_channels = 12  \n",
    "num_time_samples = 100  \n",
    "support_size = 40  # Number of support samples per user\n",
    "query_size = 40    # Number of query samples per user\n",
    "model_epochs=100\n",
    "model_dropout=0.4\n",
    "model_kern=16\n",
    "model_f1=16\n",
    "model_f2=16\n",
    "model_d=4\n",
    "metatrain_iter = 50  # Number of MAML updates\n",
    "innertrain_iter = 5  # Number of inner gradient updates\n",
    "fine_tune_steps = 5  # Number of iterations for fine-tuning\n",
    "pretrain_lr = 0.001    # Inner loop learning rate\n",
    "inner_lr = 0.001    # Inner loop learning rate\n",
    "meta_lr = 0.001    # Meta-learning rate\n",
    "num_tasks = 5\n",
    "\n",
    "user_data = generate_user_data(num_users, num_samples, num_channels, num_time_samples, support_size, query_size)\n",
    "model_params = [num_channels, num_time_samples, model_dropout, model_kern, model_f1, model_d, model_f2]\n",
    "\n",
    "keys = list(user_data.keys())\n",
    "for i in range(num_users):\n",
    "    test_users = [x for x in keys if x != i]\n",
    "    shuffled_users = random.sample(test_users, len(test_users))\n",
    "    meta_users = shuffled_users[:num_tasks]\n",
    "    unseen_users = shuffled_users[num_tasks:]\n",
    "    maml = MAML(model_params, input_shape=(num_channels, num_time_samples, 1), num_classes=num_classes, inner_lr=inner_lr,\n",
    "                outer_lr=meta_lr, inner_steps=innertrain_iter, outer_steps=metatrain_iter, fine_tune_steps = fine_tune_steps,\n",
    "                num_users=num_tasks, support_size=support_size, query_size=query_size)\n",
    "    meta_model = maml.train(user_data,i,meta_users,pretrain_lr=pretrain_lr, pretrain=False)\n",
    "    meta_model.save_weights('model_weights/maml/model')\n",
    "    maml.test_model(model_params, user_data, meta_users)\n",
    "    maml.test_model(model_params, user_data, unseen_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
